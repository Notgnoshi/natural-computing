\documentclass{article}
\input{../homework.sty}

\title{Homework 1}
\author{Austin Gill}

\begin{document}
\maketitle

\todoinline{
    Any comments applying to the whole homework?
}

\section{}\label{prob:1}

\subsection{Statement}
Compare the effectiveness of the text's iterated hill climbing and simulated annealing algorithms
to find the max of
\[ f(x) = 2^{-2{\left(\frac{(x - 0.1)}{0.9}\right)}^2}{\big(\sin(5\pi x)\big)}^6\]
with $x\in [0,1]$. Use a real valued representation. Include a plot of the function with the
location of the max and a plot of the estimate as a function of the iteration number. How sensitive
are the algorithms to initial values?

\subsection{Method}

\subsubsection{Problem Setup and Gradient Methods}

For completeness and curiosity, I chose to attack the problem from a symbolic perspective first.
This gives an opportunity to get comfortable with the problem, and get my workflow setup correctly
because I've recently reinstalled Ubuntu and subsequently all of my commonly used Python libraries.

The python \mintinline{python}{sympy} library provides decent symbolic computation capabilities
that I have had good luck with in the past. The only real surprising implementation detail is in
the definition of the objective function.

\begin{minted}[highlightlines={7-8}]{python}
def f(x):
    """The objective function to evaluate.

    This function returns a sympy symbolic function, float, or np.ndarray
    depending on the type of the input.
    """
    # Use symbolic sine, pi if necessary.
    sin, pi = (sympy.sin, sympy.pi) if isinstance(x, sympy.Symbol) else (np.sin, np.pi)

    return 2 ** (-2 * ((x - 0.1) / 0.9) ** 2) * sin(5 * pi * x) ** 6
\end{minted}

If the given type is a symbolic variable, return a symbolic representation of the function rather
than the default numerical computation. Then this function can be given individual float values,
numpy arrays, and sympy symbols.

\begin{figure}[h]
    \centering
    % Make sure to run the notebook before this will compile.
    \includegraphics{prob1/figures/prob1-function.pdf}
    \caption{The objective function $f(x)$}\label{fig:prob1:function}
\end{figure}

The very first thing to do when dealing with optimizing a function is to plot anything you can get
your hands on, including the neighbor's cat. The objective function and its derivative are shown in
\autoref{fig:prob1:function} and \autoref{fig:prob1:derivative} respectively.

\begin{figure}[h]
    \centering
    \includegraphics{prob1/figures/prob1-derivative.pdf}
    \caption{The objective function's derivative}\label{fig:prob1:derivative}
\end{figure}

We can immediately pick out the local and global extrema by visual inspection. The maxima
periodically occur at $\frac{n}{5} - \frac{1}{10}$ with the global maximum occuring at
$\frac{1}{10}$. The minima periodically occur at $\frac{n}{5}$ with value $0$.

We can produce a symbolic version of the objective function easily with
\begin{minted}{python}
    x = sympy.Symbol('x')
    print(f(x))
\end{minted}
which displays\footnote{When coerced with \mintinline{python}{sympy.init_printing()} in a Jupyter
    notebook.}
\[2^{- 2 {\left(1.11 x - 0.11\right)}^{2}} \sin^{6}{\left (5 \pi x
        \right)}\]
Then we compute the atrocious derivative symbolically.
\begin{minted}{python}
    fp = sympy.diff(f(x), x)
    print(fp)
\end{minted}
which displays the trivial derivative
% This garbage is what sympy + my autoformatter gives. I'm not fixing it.
\[2^{- 2 \left(1.11 x - 0.11\right)^{2}} \left(- 4.938 x +
    0.4938\right) \log{\left (2 \right )} \sin^{6}{\left (5 \pi x \right )} + 30 \cdot
    2^{-2
            \left(1.11 x - 0.11\right)^{2}} \pi \sin^{5}{\left (5 \pi
        x\right)}\cos{\left(5 \pi x \right )}\]
which we can then set equal to $0$ and solve
\begin{minted}{python}
    # solve f'(x) = 0
    print(sympy.solveset(fp, x))
\end{minted}
to get $\frac{n}{5} - \frac{1}{10}$ after simplification
% ditto
\[\left\{x \mid x \in \mathbb{C} \wedge \left(\left(- 4.938 x + 0.4938\right) \log{\left (2
            \right)} \sin{\left (5 \pi x \right )} + 30 \pi \cos{\left (5 \pi x \right )}\right)
    \sin^{5}{\left (5
        \pi x \right )} = 0 \right\} \setminus \left\{x \mid x \in \mathbb{C} \wedge 2^{2
            \left(1.11 x -
            0.11\right)^{2}} = 0 \right\}\]

It's also helpful to compare the results of your typical gradient optimization method against the
methods discussed later in this report.

\begin{minted}{python}
    # Convert the symbolic derivative to a numpy-compatable function for plotting.
    fp = sympy.lambdify([x], fp, 'numpy')

    # Minimizing -f(x) will maximize it.
    result = scipy.optimize.minimize(lambda x: -f(x), 0.19, bounds=[(0, 1)])
    print(result.x)
    result = scipy.optimize.minimize(lambda x: -f(x), 0.2, bounds=[(0, 1)])
    print(result.x)
    result = scipy.optimize.minimize(lambda x: -f(x), 0.21, bounds=[(0, 1)])
    print(result.x)
\end{minted}
\vspace{-1cm}
\begin{minted}{text}
    0.1
    0.2
    0.29953865
\end{minted}
\vspace{-1cm}

On either side of the minima at $x = 0.2$ the gradient optimizer\footnote{The optimization
    algorithm scipy chose for this function was the L-BFGS-B algorithm. I don't know anything about
    how well and under what conditions it performs, but I assume it works better than anything I
    could write by hand.} finds the next closest local maxima. This agrees with my intuitive
understanding of gradient methods; without some kind of correction, they too are susceptible to
finding local optima of oscillatory functions.

\subsubsection{Hill Climbing}

This hill climbing algorithm discussed in the book is listed in \autoref{alg:hill-climbing}.

\begin{algorithm}
    % \begin{noindent}
    \begin{algorithmic}
        \Function{hill-climbing}{$f$}
            \State{Initialize $x$}
            \While{not done}\IComment{can be convergence or fixed iteration}
                \State{$x' = x + \text{perturbation}$}
                \If{$f(x') < f(x)$}\IComment{this minimizes $f(x)$}
                    \State{$x = x'$}
                \EndIf{}
            \EndWhile{}
            \State\Return{$x$}
        \EndFunction{}
    \end{algorithmic}
    % \end{noindent}
    \caption{The hill climbing algorithm}\label{alg:hill-climbing}
\end{algorithm}

This can easily be implemented in Python as

\begin{minted}{python}
    def hill_climbing(func, bounds, sigma, iters):
        """Minimize the given function using the Hill Climbing algorithm.

        :param func: The function to minimize.
        :param bounds: The lower and upper bounds on the feasible region.
        :param sigma: The standard deviation to use when perturbing the current guess.
        :param iters: The number of iterations to run the hill climbing algorithm for.
        :returns: The path of points visited from the initial guess to the final solution.
        """
        path = np.zeros(iters)
        x0 = np.random.uniform(*bounds)
        for i in range(iters):
            xp = perturb(x0, bounds, sigma)
            if func(xp) < func(x0):
                x0 = xp
            path[i] = x0
        return path
\end{minted}

with \mintinline{python}{perturb(x)} defined as

\begin{minted}{python}
    def perturb(x, bounds, sigma):
        """Perturb the given value by adding zero-mean white noise.

        :param x: The value to perturb.
        :param bounds: The lower and upper bounds on the feasible region.
        :param sigma: The standard deviation to use when adding white noise.
        """
        m, M = bounds
        xp = x + np.random.normal(scale=sigma)
        while xp >= M or xp <= m:
            xp = x + np.random.normal(scale=sigma)
        return xp
\end{minted}

Note that my implementation of \mintinline{python}{perturb(x)} will not perturb the given point
outside of the feasible region for the problem.

One of the easiest ways to improve the quality of the results from the hill climbing algorithm is
to run it multiple times and take the best result. This is the iterated hill climbing algorithm
from the book, listed in \autoref{alg:iterated-hill-climbing}.

\begin{algorithm}
    % \begin{noindent}
    \begin{algorithmic}
        \Function{iterated-hill-climbing}{$f, n$}
            \State{$solutions = map\big(\Call{hill-climbing}{f}, \{1, \dots, n\}\big)$}\IComment{A trivially parallelizable operation}
            \State\Return{The best solution}
        \EndFunction{}
    \end{algorithmic}
    % \end{noindent}
    \caption{The iterated hill climbing algorithm}\label{alg:iterated-hill-climbing}
\end{algorithm}

This algorithm can easily (even with parallelization) be implemented in Python as follows
\begin{minted}[highlightlines={18}]{python}
import itertools
import multiprocessing
# I wonder why it's called dummy?
from multiprocessing.dummy import Pool as ThreadPool

def iterated_hill_climbing(func, bounds, sigma, inner_iters, iters):
    """Repeatedly climb the hill to find the less-local extremum.

    :param func: The function to minimize.
    :param bounds: The lower and upper bounds on the feasible region.
    :param sigma: The standard deviation to use when perturbing the current guess.
    :param inner_iters: The number of iterations to use for each run of the algorithm.
    :param iters: The number of times to run the algorithm.
    :returns: An array of solutions from each run, sorted by their fitness.
    """
    pool = ThreadPool(multiprocessing.cpu_count())
    # starmap consumes the given iterable in parallel until it is exhausted, collecting the results.
    results = pool.starmap(hill_climbing, itertools.repeat((func, bounds, sigma, inner_iters), times=iters))
    # Each result is a full path, not the optimal value
    optimums = [r[-1] for r in results]
    # Sort the optimums by their fitness.
    optimums.sort(key=func)
    return np.array(optimums)
\end{minted}
This implementation runs the desired number of iterations in parallel using as many threads as you
have processors before collecting all of the results and sorting the optimums by the objective
function.

\subsubsection{Simulated Annealing}

\begin{algorithm}
    % \begin{noindent}
    \begin{algorithmic}
        \Function{simulated-annealing}{$f$}
            \State{Initialize $T$}
            \State{Initialize $x$}
            \While{not done}\IComment{prefer convergence over fixed iteration}
                \State{$x' = x + \text{perturbation}$ }
                \If{$\displaystyle rand(0, 1) < e^{\left(f(x) - f(x')\right)\over T}$}
                    \State{$x = x'$}
                \EndIf{}
                \State{Update $T$}
            \EndWhile{}
            \State\Return{$x$}
        \EndFunction{}
    \end{algorithmic}
    % \end{noindent}
    \caption{The simulated annealing algorithm}\label{alg:simulated-annealing}
\end{algorithm}

\begin{algorithm}
    % \begin{noindent}
    \begin{algorithmic}
        \Function{iterated-simulated-annealing}{$f, n$}
            \State{$solutions = map\big(\Call{simulated-annealing}{f}, \{1, \dots, n\}\big)$}\IComment{A trivially parallelizable operation}
            \State\Return{The best solution}
        \EndFunction{}
    \end{algorithmic}
    % \end{noindent}
    \caption{The iterated simulated annealing algorithm}\label{alg:iterated-simulated-annealing}
\end{algorithm}

\todoinline{
    Implement \autoref{alg:simulated-annealing} and plot results.
}

\subsection{Results}
\todoinline{
    \begin{itemize}
        \item Plot the function.
        \item Plot the estimate of the max as a function of the iteration number.
        \item Examine the sensitivity to the initial values.
    \end{itemize}
}

\subsubsection{Hill Climbing}

\subsubsection{Simulated Annealing}

\section{}\label{prob:2}
\subsection{Statement}
In lecture we addressed the Traveling Salesman Problem using Simulated Annealing. To speed up
convergence and increase the odds of finding the global extremal, it makes sense to try an
evolutionary algorithm. The mutation operator can be adapted from the SA algorithm. Skip
recombination in this problem. Write an evolutionary algorithm to solve the TSP as generated in the
sample program. Compare deterministic and stochastic selection operators.

\subsection{Method}
\todoinline{
    Outline the method(s) used to implement the selection operator.

    Summarize the evolutionary algorithm.
}
\subsection{Experiments}
\todoinline{
    Write an evolutionary algorithm, and steal the mutation operator from the SA algorithm.

    Compare deterministic and stochastic selection operators.
}
\subsubsection{Experiment 1}
\subsubsection{Experiment 2}

\subsection{Results}
\todoinline{
    Compare solutions

    Compare selection operators
}

\section{}\label{prob:3}
\subsection{Statement}
In \autoref{prob:2} we implemented EA code to solve the Traveling Salesman Problem. In this
problem, implement recombination (crossover) in your EA. For this problem you will need to use an
encoding that prevents crossover that creates an invalid candidate. As before, compare
deterministic and stochastic selection operators.

\subsection{Method}
\todoinline{
    Implement crossover.

    Find the right encoding for the problem?
}

\subsection{Experiments}

\subsubsection{Experiment 1}
\subsubsection{Experiment 2}

\subsection{Results}
\todoinline{
    Compare selection operators.
}

\end{document}
